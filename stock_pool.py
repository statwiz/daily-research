import pywencai
import re
import pandas as pd
import numpy as np
import time
import os
from datetime import datetime, timedelta
from log_setup import get_logger
from trading_calendar import TradingCalendar
from notification import DingDingRobot
from wencai import WencaiUtils
from utils import execute_with_retry
import warnings
warnings.filterwarnings("ignore")


class StockPoolConfig:
    """è‚¡ç¥¨æ± é…ç½®ç±»"""
    # é‡è¯•é…ç½®
    MAX_RETRY_COUNT = 3
    RETRY_BASE_DELAY = 2  # åŸºç¡€ç­‰å¾…æ—¶é—´ï¼Œå®é™…ç­‰å¾…æ—¶é—´ä¸º (attempt + 1) * BASE_DELAY
    
    # åŒºé—´é…ç½® [(å¤©æ•°, æ’å)]
    INTERVAL_CONFIGS = [
        (2, 10),   # æœ€è¿‘2æ—¥å‰10å
        (3, 10),   # æœ€è¿‘3æ—¥å‰10å  
        (5, 10),   # æœ€è¿‘5æ—¥å‰10å
        (10, 10),   # æœ€è¿‘10æ—¥å‰10å
        (15, 5),   # æœ€è¿‘15æ—¥å‰5å
    ]
    
    # é‡è¦åº¦è®¡ç®—å‚æ•°
    IMPORTANCE_ALPHA = 0.99  # æ’åæƒé‡ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒæ’åå·®è·
    IMPORTANCE_BETA = 0.01   # åŒºé—´é•¿åº¦æƒé‡ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒçŸ­åŒºé—´
    
    # æ•°æ®ä¿å­˜é…ç½®
    DATA_SAVE_DIR = 'data'
    CSV_SUBDIR = 'csv'
    TXT_SUBDIR = 'txt'
    DATA_FILE_PREFIX = 'stock_pool'

    # æŸ¥è¯¢ç­‰å¾…æ—¶é—´
    QUERY_SLEEP_SECONDS = 3
    MAIN_RETRY_SLEEP_SECONDS = 10


# å…¨å±€å¯¹è±¡
trading_calendar = TradingCalendar()
dingding_robot = DingDingRobot()
logger = get_logger("stock_pool", "logs", "daily_research.log")


class StockPool:
    """è‚¡ç¥¨æ± ç±» - ç»Ÿä¸€ç®¡ç†è‚¡ç¥¨æ± æ•°æ®çš„è·å–ã€è®¡ç®—ã€ä¿å­˜å’Œåˆ†æ"""
    
    def __init__(self):
        """åˆå§‹åŒ–è‚¡ç¥¨æ± å¯¹è±¡"""
        self.trading_calendar = trading_calendar
        self.dingding_robot = dingding_robot
        self.logger = logger


    def read_stock_pool_data(self, date_str: str = None) -> pd.DataFrame:
        """è¯»å–è‚¡ç¥¨æ± æ•°æ®"""
        if date_str is None:
            date_str = trading_calendar.get_default_trade_date()
        csv_path = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}/stock_pool/core_stocks_{date_str}.csv"
        return pd.read_csv(csv_path, dtype={'code': str, 'market_code': str})
        
    def save_stock_pool_data(self, df: pd.DataFrame, date_str: str = None,prefix: str = 'core_stocks',
                            market_value_threshold: float = 100) -> dict:
        """
        ä¿å­˜è‚¡ç¥¨æ± æ•°æ®åˆ°CSVå’ŒTXTæ–‡ä»¶
        
        Args:
            df: è¦ä¿å­˜çš„DataFrame
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
            market_value_threshold: å¸‚å€¼ç­›é€‰é˜ˆå€¼ï¼ˆäº¿å…ƒï¼‰
        
        Returns:
            dict: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ä¿¡æ¯
        """
        if date_str is None:
            date_str = trading_calendar.get_default_trade_date()
        
        self.logger.info(f"å¼€å§‹ä¿å­˜è‚¡ç¥¨æ± æ•°æ®, æ•°æ®é‡: {len(df)}")
        saved_paths = {}
        
        # åˆ›å»ºæ‰€éœ€çš„ç›®å½•ç»“æ„
        os.makedirs(f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}/stock_pool", exist_ok=True)
        os.makedirs(f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.TXT_SUBDIR}/stock_pool", exist_ok=True)
        
        if df.empty:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼Œè·³è¿‡ä¿å­˜")
            return saved_paths
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        if 'code' not in df.columns:
            raise ValueError("DataFrameä¸­ç¼ºå°‘'code'åˆ—")
        
        # ä¿å­˜å…¨é‡æ•°æ®åˆ°CSV
        csv_path = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}/stock_pool/{prefix}_{date_str}.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        saved_paths['main_csv'] = csv_path
        self.logger.info(f"è‚¡ç¥¨æ± å…¨é‡CSVä¿å­˜å®Œæˆ, è·¯å¾„: {csv_path}")
        
        # ä¿å­˜å…¨é‡ä»£ç åˆ°TXT
        stock_codes = df['code'].astype(str).str.zfill(6).tolist()
        txt_path = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.TXT_SUBDIR}/stock_pool/{prefix}_{date_str}.txt"
        with open(txt_path, 'w', encoding='utf-8') as f:
            for code in stock_codes:
                f.write(f"{code}\n")
        saved_paths['main_txt'] = txt_path
        self.logger.info(f"è‚¡ç¥¨æ± å…¨é‡ç‰ˆä»£ç ä¿å­˜å®Œæˆ, è·¯å¾„: {txt_path}")
        
        # å¦‚æœæœ‰å¸‚å€¼åˆ—ï¼Œä¿å­˜ä¸­å†›ç‰ˆ
        if 'å¸‚å€¼Z' in df.columns:
            threshold_value = market_value_threshold * 1e8
            filtered_df = df[df['å¸‚å€¼Z'] > threshold_value]
            self.logger.info(f"ç­›é€‰å‡ºå¤§äº{market_value_threshold}äº¿è‡ªç”±æµé€šå¸‚å€¼çš„è‚¡ç¥¨æ•°é‡: {len(filtered_df)}")
            
            if len(filtered_df) > 0:
                # ä¿å­˜ä¸­å†›ç‰ˆCSV
                filtered_csv_path = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}/stock_pool/{prefix}_zj_{date_str}.csv"
                filtered_df.to_csv(filtered_csv_path, index=False, encoding='utf-8-sig')
                saved_paths['filtered_csv'] = filtered_csv_path
                self.logger.info(f"è‚¡ç¥¨æ± ä¸­å†›ç‰ˆCSVä¿å­˜å®Œæˆ, è·¯å¾„: {filtered_csv_path}")
                
                # ä¿å­˜ä¸­å†›ç‰ˆä»£ç åˆ°TXT
                filtered_stock_codes = filtered_df['code'].astype(str).str.zfill(6).tolist()
                filtered_txt_path = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.TXT_SUBDIR}/stock_pool/{prefix}_zj_{date_str}.txt"
                with open(filtered_txt_path, 'w', encoding='utf-8') as f:
                    for code in filtered_stock_codes:
                        f.write(f"{code}\n")
                saved_paths['filtered_txt'] = filtered_txt_path
                self.logger.info(f"è‚¡ç¥¨æ± ä¸­å†›ç‰ˆä»£ç ä¿å­˜å®Œæˆ, è·¯å¾„: {filtered_txt_path}")
            else:
                self.logger.warning(f"æ²¡æœ‰æ‰¾åˆ°å¤§äº{market_value_threshold}äº¿è‡ªç”±æµé€šå¸‚å€¼çš„è‚¡ç¥¨ï¼Œè·³è¿‡ä¸­å†›ç‰ˆæ•°æ®ä¿å­˜")
        
        return saved_paths

    def compare_with_previous_trading_day(self, current_df: pd.DataFrame, date_str: str = None) -> str:
        """ä¸å‰ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®è¿›è¡Œå¯¹æ¯”ï¼Œè¿”å›å¯¹æ¯”æ¶ˆæ¯ï¼Œå¹¶ä¿å­˜æ–°å¢å’Œå‡å°‘çš„è‚¡ç¥¨æ•°æ®"""
        if date_str is None:
            date_str = trading_calendar.get_default_trade_date()
        
        # è·å–å‰ä¸€äº¤æ˜“æ—¥æ•°æ®
        previous_date = self.trading_calendar.get_previous_trading_day(date_str)
        if not previous_date:
            return f"ğŸ“Š ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å®Œæˆ\næ•°æ®é‡: {len(current_df)}åªè‚¡ç¥¨\nâš ï¸ æœªæ‰¾åˆ°å‰ä¸€äº¤æ˜“æ—¥æ•°æ®"
        
        # æŸ¥æ‰¾å‰ä¸€äº¤æ˜“æ—¥çš„CSVæ–‡ä»¶
        previous_date_str = previous_date.strftime('%Y%m%d')
        previous_file = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}/stock_pool/core_stocks_{previous_date_str}.csv"
        
        if not os.path.exists(previous_file):
            return f"ğŸ“Š ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å®Œæˆ\næ•°æ®é‡: {len(current_df)}åªè‚¡ç¥¨\nâš ï¸ æœªæ‰¾åˆ°å‰ä¸€äº¤æ˜“æ—¥æ•°æ®æ–‡ä»¶"
        
        try:
            # è¯»å–CSVæ–‡ä»¶ï¼ŒæŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹ä»¥ä¿æŒå‰å¯¼é›¶
            previous_df = pd.read_csv(previous_file, dtype={'code': str, 'market_code': str})
        except Exception as e:
            self.logger.warning(f"è¯»å–å‰ä¸€äº¤æ˜“æ—¥æ•°æ®å¤±è´¥: {e}")
            return f"ğŸ“Š ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å®Œæˆ\næ•°æ®é‡: {len(current_df)}åªè‚¡ç¥¨\nâš ï¸ è¯»å–å‰ä¸€äº¤æ˜“æ—¥æ•°æ®å¤±è´¥"
        
        # åŸºäºè‚¡ç¥¨ä»£ç è®¡ç®—å˜åŠ¨ï¼ˆç¡®ä¿å”¯ä¸€æ€§ï¼‰
        current_codes = set(current_df['code'].astype(str))
        previous_codes = set(previous_df['code'].astype(str))
        
        # è·å–æ–°å¢å’Œç§»é™¤çš„è‚¡ç¥¨ä»£ç 
        new_codes = current_codes - previous_codes
        removed_codes = previous_codes - current_codes
        
        # ä¿å­˜æ–°å¢å’Œå‡å°‘çš„è‚¡ç¥¨æ•°æ®åˆ°CSVæ–‡ä»¶
        save_dir = f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}/stock_pool"
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜æ–°å¢è‚¡ç¥¨æ•°æ®
        if len(new_codes) > 0:
            new_stocks_df = current_df[current_df['code'].astype(str).isin(new_codes)].copy()
            new_stocks_df = new_stocks_df.sort_values('é‡è¦åº¦', ascending=False)
            add_file_path = f"{save_dir}/add_{date_str}.csv"
            new_stocks_df.to_csv(add_file_path, index=False, encoding='utf-8-sig')
            self.logger.info(f"æ–°å¢è‚¡ç¥¨æ•°æ®ä¿å­˜å®Œæˆ, è·¯å¾„: {add_file_path}, æ•°é‡: {len(new_stocks_df)}")
        
        # ä¿å­˜å‡å°‘è‚¡ç¥¨æ•°æ®
        if len(removed_codes) > 0:
            removed_stocks_df = previous_df[previous_df['code'].astype(str).isin(removed_codes)].copy()
            removed_stocks_df = removed_stocks_df.sort_values('é‡è¦åº¦', ascending=False)
            remove_file_path = f"{save_dir}/remove_{date_str}.csv"
            removed_stocks_df.to_csv(remove_file_path, index=False, encoding='utf-8-sig')
            self.logger.info(f"å‡å°‘è‚¡ç¥¨æ•°æ®ä¿å­˜å®Œæˆ, è·¯å¾„: {remove_file_path}, æ•°é‡: {len(removed_stocks_df)}")
        
        # æ„å»ºåŸºç¡€æ¶ˆæ¯
        date_fmt = f"{previous_date.strftime('%Y-%m-%d')}"
        message = [
            "ğŸ“Š æ¯æ—¥å¤ç›˜:è‚¡ç¥¨æ± ",
            f"ğŸ“… å¯¹æ¯”åŸºå‡†: {date_fmt}",
            f"ğŸ“ˆ ä»Šæ—¥: {len(current_codes)}åª | æ˜¨æ—¥: {len(previous_codes)}åª"
        ]
        
        if len(new_codes) == 0 and len(removed_codes) == 0:
            message.append("âœ¨ è‚¡ç¥¨æ± æ— å˜åŠ¨")
        else:
            # æ–°å¢è‚¡ç¥¨è¯¦æƒ…
            if len(new_codes) > 0:
                message.append(f"ğŸ†• æ–°å¢: {len(new_codes)}åª")
                
                # è·å–æ–°å¢è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
                new_stocks_info = current_df[current_df['code'].astype(str).isin(new_codes)].copy()
                new_stocks_info = new_stocks_info.sort_values('é‡è¦åº¦', ascending=False)
                
                for _, stock in new_stocks_info.iterrows():
                    code = stock['code']
                    name = stock['è‚¡ç¥¨ç®€ç§°']
                    interval_info = stock.get('åŒºé—´ä¿¡æ¯', 'æ— ')
                    message.append(f"  â€¢ {name}({code}) åŒºé—´:{interval_info}")
            
            # ç§»é™¤è‚¡ç¥¨ç»Ÿè®¡
            if len(removed_codes) > 0:
                message.append(f"ğŸ”» ç§»é™¤: {len(removed_codes)}åª")
                
                # è·å–ç§»é™¤è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä»å‰ä¸€å¤©çš„æ•°æ®ä¸­ï¼‰
                removed_stocks_info = previous_df[previous_df['code'].astype(str).isin(removed_codes)].copy()
                removed_stocks_info = removed_stocks_info.sort_values('é‡è¦åº¦', ascending=False)
                
                for _, stock in removed_stocks_info.iterrows():
                    code = stock['code']
                    name = stock['è‚¡ç¥¨ç®€ç§°']
                    interval_info = stock.get('åŒºé—´ä¿¡æ¯', 'æ— ')
                    message.append(f"  â€¢ {name}({code}) åŒºé—´:{interval_info}")
        
        msg = "\n".join(message)
        self.logger.info(msg)
        return msg

    def calc_importance(self, df: pd.DataFrame, 
                       alpha: float = None, 
                       beta: float = None) -> pd.DataFrame:
        """
        åŸºäºåŸå§‹æ•°æ®èšåˆå¹¶è®¡ç®—è‚¡ç¥¨é‡è¦åº¦
        
        Args:
            df: åŒ…å«è‚¡ç¥¨åŒºé—´æ•°æ®çš„DataFrame
            alpha: æ’åæƒé‡å‚æ•°ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒæ’åå·®è·
            beta: åŒºé—´é•¿åº¦æƒé‡å‚æ•°ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒçŸ­åŒºé—´
        
        Returns:
            æŒ‰é‡è¦åº¦æ’åºçš„DataFrameï¼ŒåŒ…å«åŒºé—´ä¿¡æ¯å’Œé‡è¦åº¦å¾—åˆ†
            
        è®¡ç®—é€»è¾‘:
            1. åˆ†ç»„å­—æ®µ: [äº¤æ˜“æ—¥æœŸ, è‚¡ç¥¨ç®€ç§°, market_code, code]
            2. åŒºé—´ä¿¡æ¯: 'åŒºé—´é•¿åº¦-åŒºé—´æ’å' ç”¨ | è¿æ¥
            3. é‡è¦åº¦: 100 * sum(exp(-alpha * æ’å) * exp(-beta * åŒºé—´é•¿åº¦))
            4. æ’åº: æŒ‰é‡è¦åº¦é™åº
        """
        # ä½¿ç”¨é…ç½®é»˜è®¤å€¼
        if alpha is None:
            alpha = StockPoolConfig.IMPORTANCE_ALPHA
        if beta is None:
            beta = StockPoolConfig.IMPORTANCE_BETA
        
        self.logger.info(f"å¼€å§‹è®¡ç®—è‚¡ç¥¨é‡è¦åº¦, æ•°æ®é‡: {len(df)}, alpha: {alpha}, beta: {beta}")
        start_time = time.time()
        
        def aggregate_importance(sub_df):
            """èšåˆå‡½æ•°ï¼šè®¡ç®—å•åªè‚¡ç¥¨çš„é‡è¦åº¦"""
            interval_info = "|".join(
                f"{length}-{rank}" for length, rank in zip(sub_df["åŒºé—´é•¿åº¦"], sub_df["åŒºé—´æ’å"])
            )
            # é‡è¦åº¦è®¡ç®—ï¼šä½¿ç”¨å¯¹æ•°å‡½æ•°
            importance_score = float(
                100 * (1 / (np.log1p(sub_df["åŒºé—´æ’å"]) * np.log1p(sub_df["åŒºé—´é•¿åº¦"]))).sum()
            )

            return pd.Series({
                "åŒºé—´ä¿¡æ¯": interval_info,
                "é‡è¦åº¦": importance_score
            })

        # æŒ‰è‚¡ç¥¨åˆ†ç»„å¹¶è®¡ç®—é‡è¦åº¦
        grouped_df = (
            df.groupby(["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ç®€ç§°", "å¸‚å€¼Z", "market_code", "code"], as_index=False)
            .apply(aggregate_importance)
        )

        # æŒ‰é‡è¦åº¦é™åºæ’åº
        grouped_df.sort_values(by="é‡è¦åº¦", ascending=False, inplace=True)
        grouped_df.reset_index(drop=True, inplace=True)
        
        processing_time = time.time() - start_time
        self.logger.info(f"é‡è¦åº¦è®¡ç®—å®Œæˆ, è€—æ—¶: {processing_time:.2f}ç§’, ç»“æœæ•°é‡: {len(grouped_df)}")
        
        return grouped_df[["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ç®€ç§°", "å¸‚å€¼Z", "market_code", "code", "åŒºé—´ä¿¡æ¯", "é‡è¦åº¦"]]

    def get_muti_top_stocks(self, selected=None):
        """
        è·å–è‚¡ç¥¨æ± æ•°æ®ï¼Œé€šè¿‡å¤šä¸ªæ—¶é—´åŒºé—´ç»„åˆè®¡ç®—é‡è¦åº¦
        
        Args:
            selected: æ˜¯å¦ä½¿ç”¨ç­›é€‰æ¡ä»¶ï¼ˆéSTã€éé€€å¸‚ç­‰ï¼‰
        
        Returns:
            æŒ‰é‡è¦åº¦æ’åºçš„è‚¡ç¥¨æ± DataFrame
        """
        try:
            all_df = []
            # ä½¿ç”¨é…ç½®ç±»ä¸­çš„åŒºé—´è®¾ç½®
            for days, rank in StockPoolConfig.INTERVAL_CONFIGS:
                self.logger.info(f'========== selected: {selected}  {days}-{rank} ===========')
                df = execute_with_retry(WencaiUtils.get_top_stocks, 
                                       max_retry_count=StockPoolConfig.MAX_RETRY_COUNT,
                                       retry_base_delay=StockPoolConfig.RETRY_BASE_DELAY,
                                       days=days, rank=rank, use_filters=selected)
                if df is None or df.empty:
                    raise Exception(f'{(days,rank)}è·å–æ•°æ®å¤±è´¥')
                all_df.append(df)
                time.sleep(StockPoolConfig.QUERY_SLEEP_SECONDS)
            
            df_all = pd.concat(all_df)
            df = self.calc_importance(df_all, 
                               alpha=StockPoolConfig.IMPORTANCE_ALPHA, 
                               beta=StockPoolConfig.IMPORTANCE_BETA)
            return df
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨æ± å¤±è´¥: {e}")
            return None


    def get_core_stocks_data(self) -> pd.DataFrame:
        """
        è·å–æ‰€æœ‰æ ¸å¿ƒè‚¡ç¥¨æ± æ•°æ®
        
        Returns:
            åŒ…å«æ‰€æœ‰è‚¡ç¥¨æ± DataFrameçš„åˆ—è¡¨
        """
        try:
            data_list = []
            
            # è‚¡ç¥¨æ± é…ç½®ï¼š(ç­›é€‰æ¡ä»¶, æè¿°)
            pool_configs = [
                (None, "å…¨é‡è‚¡ç¥¨æ± æ•°æ®"),
                ('30', "ç­›é€‰åè‚¡ç¥¨æ± æ•°æ®: è‡ªç”±æµé€šå¸‚å€¼>30äº¿"),  
                ('60', "ç­›é€‰åè‚¡ç¥¨æ± æ•°æ®: è‡ªç”±æµé€šå¸‚å€¼>60äº¿"),
                ('100', "ç­›é€‰åè‚¡ç¥¨æ± æ•°æ®: è‡ªç”±æµé€šå¸‚å€¼>100äº¿"),
                ('200', "ç­›é€‰åè‚¡ç¥¨æ± æ•°æ®: è‡ªç”±æµé€šå¸‚å€¼>200äº¿"),
            ]
            
            for i, (selected, description) in enumerate(pool_configs, 1):
                step_name = "æ­¥éª¤1" if selected is None else f"æ­¥éª¤2.{i-1}"
                self.logger.info(f" ------------ {step_name}: è·å–{description} ------------")
                
                data = self.get_muti_top_stocks(selected=selected)
                if data is None or data.empty:
                    self.logger.warning(f"{description}è·å–å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                    return None  # ä»»ä½•ä¸€ä¸ªè·å–å¤±è´¥å°±è¿”å›None
                
                self.logger.info(f'{description}è·å–æˆåŠŸ, æ•°æ®é‡: {data.shape}')
                data_list.append(data)
            if len(data_list) == 0:
                return None
            combined_df = pd.concat(data_list, ignore_index=True)
            
            # æŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œä¿ç•™é‡è¦åº¦æœ€é«˜çš„è®°å½•
            groupby_keys = ['äº¤æ˜“æ—¥æœŸ', 'è‚¡ç¥¨ç®€ç§°', 'å¸‚å€¼Z', 'market_code', 'code']
            max_importance_idx = combined_df.groupby(groupby_keys)['é‡è¦åº¦'].idxmax()
            df = (combined_df.loc[max_importance_idx]
                    .sort_values(by='é‡è¦åº¦', ascending=False)
                    .reset_index(drop=True))
            df['é‡è¦åº¦'] = df['é‡è¦åº¦'].round(2)
            return df
        except Exception as e:
            self.logger.error(f"è·å–æ ¸å¿ƒè‚¡ç¥¨æ± æ•°æ®å¤±è´¥: {e}")
            return None

    def get_first_breakout_stocks(self):
        """
        è·å–é¦–æ¿è‚¡ç¥¨æ± æ•°æ®
        """
        try:
            self.logger.info("å¼€å§‹è·å–æ‰€æœ‰çš„é¦–æ¿è‚¡ç¥¨æ± æ•°æ®")
            df = execute_with_retry(WencaiUtils.get_first_breakout_stocks, 
                                   use_filters=False)
            if df is None or df.empty:
                raise Exception("è·å–æ‰€æœ‰é¦–æ¿è‚¡ç¥¨æ± æ•°æ®å¤±è´¥")
            self.logger.info(f"æ‰€æœ‰é¦–æ¿è‚¡ç¥¨æ± æ•°æ®é‡: {len(df)}")
            # ä¿å­˜æ‰€æœ‰é¦–æ¿è‚¡ç¥¨æ± æ•°æ®
            # self.save_stock_pool_codes(df, trade_date)
            self.logger.info("å¼€å§‹è·å–è‡ªç”±æµé€šå¸‚å€¼å¤§äº100äº¿çš„é¦–æ¿è‚¡ç¥¨æ± æ•°æ®")
            df_zj = execute_with_retry(WencaiUtils.get_first_breakout_stocks, 
                                   use_filters=True)
            if df_zj is None or df_zj.empty:
                raise Exception("è·å–è‡ªç”±æµé€šå¸‚å€¼å¤§äº100äº¿çš„é¦–æ¿è‚¡ç¥¨æ± æ•°æ®å¤±è´¥")
            self.logger.info(f"è‡ªç”±æµé€šå¸‚å€¼å¤§äº100äº¿çš„é¦–æ¿è‚¡ç¥¨æ± æ•°æ®é‡: {len(df_zj)}")
            df = pd.concat([df, df_zj])
            # å»é‡
            df = df.drop_duplicates(subset=['è‚¡ç¥¨ç®€ç§°'])
            return df
        except Exception as e:
            self.logger.error(f"è·å–é¦–æ¿è‚¡ç¥¨æ± æ•°æ®å¤±è´¥: {e}")
            return None

    def run(self):

        self.logger.info("å¼€å§‹æ‰§è¡Œè‚¡ç¥¨æ± æ•°æ®è·å–ä»»åŠ¡...")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        # today = datetime.now().strftime('%Y%m%d')
        # if not self.trading_calendar.is_trading_day(today):
        #     self.logger.info(f"ä»Šæ—¥({today})éäº¤æ˜“æ—¥ï¼Œè·³è¿‡æ‰§è¡Œ")
        #     return
        
        for i in range(StockPoolConfig.MAX_RETRY_COUNT):
            try:
                if i > 0:
                    self.logger.info(f"------------ ç¬¬{i}æ¬¡é‡è¯• ------------")
                # æ­¥éª¤1: è·å–æ ¸å¿ƒè‚¡ç¥¨æ± æ•°æ®
                core_df = self.get_core_stocks_data()
                if core_df is None or core_df.empty:
                    self.logger.warning("æ ¸å¿ƒè‚¡ç¥¨æ± æ•°æ®æ”¶é›†å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                    continue            
                # è·å–äº¤æ˜“æ—¥æœŸ
                trade_date = core_df['äº¤æ˜“æ—¥æœŸ'].iloc[0]
                # æ­¥éª¤2: ä¿å­˜é¦–æ¿è‚¡ç¥¨æ± æ•°æ®
                self.logger.info("------------ æ­¥éª¤2: ä¿å­˜é¦–æ¿è‚¡ç¥¨æ± æ•°æ®------------")
                first_stocks_df = self.get_first_breakout_stocks()
                if first_stocks_df is None or first_stocks_df.empty:
                    self.logger.warning("é¦–æ¿è‚¡ç¥¨æ± æ•°æ®æ”¶é›†å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                    continue
                self.save_stock_pool_data(first_stocks_df, trade_date, prefix='first_stocks')
                
                # æ­¥éª¤3: ä¿å­˜æ ¸å¿ƒè‚¡ç¥¨æ± æ•°æ®
                self.logger.info("------------ æ­¥éª¤2: ä¿å­˜æ ¸å¿ƒè‚¡ç¥¨æ± æ•°æ®------------")
                self.save_stock_pool_data(core_df, trade_date, prefix='core_stocks')
                
                # æ­¥éª¤4: æ•°æ®å¯¹æ¯”åˆ†æ
                self.logger.info("------------ æ­¥éª¤3: ä¸å‰ä¸€äº¤æ˜“æ—¥æ•°æ®è¿›è¡Œå¯¹æ¯”åˆ†æ------------")
                comparison_msg = self.compare_with_previous_trading_day(core_df, trade_date)
                
                # æ­¥éª¤4: å‘é€æ•°æ®å¯¹æ¯”ç»“æœåˆ°é’‰é’‰
                self.logger.info("------------ æ­¥éª¤4: å‘é€æ•°æ®å¯¹æ¯”ç»“æœåˆ°é’‰é’‰------------")
                self.logger.info(f"ä»»åŠ¡å®Œæˆ! æœ€ç»ˆæ•°æ®é‡: {core_df.shape}")
                self.dingding_robot.send_message(comparison_msg, 'robot3')
                break                        
            except Exception as e:
                if i == StockPoolConfig.MAX_RETRY_COUNT - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    error_msg = f"ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å¤±è´¥: {e}"
                    self.logger.error(f"é‡è¯•{StockPoolConfig.MAX_RETRY_COUNT}æ¬¡åä»å¤±è´¥: {e}")
                    self.dingding_robot.send_message(error_msg, 'robot3')
                else:
                    # è¿˜æœ‰é‡è¯•æœºä¼š
                    self.logger.warning(f"ç¬¬{i+1}æ¬¡å°è¯•å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•: {e}")
                
                if i < StockPoolConfig.MAX_RETRY_COUNT - 1:
                    time.sleep(StockPoolConfig.MAIN_RETRY_SLEEP_SECONDS)


def main():
    """ä¸»å‡½æ•°ï¼šä½¿ç”¨StockPoolç±»æ‰§è¡Œä»»åŠ¡"""
    stock_pool = StockPool()
    stock_pool.run()


if __name__ == "__main__":
    main()