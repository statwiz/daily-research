import pywencai
import re
import pandas as pd
from typing import Optional
import numpy as np
import time
import os
from datetime import datetime, timedelta
from log_setup import get_logger
from utils import send_dingding_msg, trading_calendar
from wencai_utils import WencaiUtils
import akshare as ak
import configparser

import warnings
warnings.filterwarnings("ignore")

# é…ç½®ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰å‚æ•°
class StockPoolConfig:
    """è‚¡ç¥¨æ± é…ç½®ç±»"""
    # é‡è¯•é…ç½®
    MAX_RETRY_COUNT = 3
    RETRY_BASE_DELAY = 2  # åŸºç¡€ç­‰å¾…æ—¶é—´ï¼Œå®é™…ç­‰å¾…æ—¶é—´ä¸º (attempt + 1) * BASE_DELAY
    
    # åŒºé—´é…ç½® [(å¤©æ•°, æ’å)]
    INTERVAL_CONFIGS = [
        (2, 10),   # æœ€è¿‘2æ—¥å‰10å
        (3, 10),   # æœ€è¿‘3æ—¥å‰10å  
        (5, 10),   # æœ€è¿‘5æ—¥å‰10å
        (10, 5),   # æœ€è¿‘10æ—¥å‰5å
        (15, 3),   # æœ€è¿‘15æ—¥å‰3å
        (20, 2)    # æœ€è¿‘20æ—¥å‰2å
    ]
    
    # é‡è¦åº¦è®¡ç®—å‚æ•°
    IMPORTANCE_ALPHA = 0.999  # æ’åæƒé‡ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒæ’åå·®è·
    IMPORTANCE_BETA = 0.001   # åŒºé—´é•¿åº¦æƒé‡ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒçŸ­åŒºé—´
    
    # æ•°æ®ä¿å­˜é…ç½®
    DATA_SAVE_DIR = 'data'
    CSV_SUBDIR = 'csv'
    TXT_SUBDIR = 'txt'
    DATA_FILE_PREFIX = 'stock_pool'
    
    @classmethod
    def get_csv_save_path(cls, date_str: str = None) -> str:
        """ç”ŸæˆCSVæ–‡ä»¶ä¿å­˜è·¯å¾„"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        return f"{cls.DATA_SAVE_DIR}/{cls.CSV_SUBDIR}/{cls.DATA_FILE_PREFIX}_{date_str}.csv"
    
    @classmethod
    def get_txt_save_path(cls, date_str: str = None) -> str:
        """ç”ŸæˆTXTæ–‡ä»¶ä¿å­˜è·¯å¾„"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        return f"{cls.DATA_SAVE_DIR}/{cls.TXT_SUBDIR}/{cls.DATA_FILE_PREFIX}_{date_str}.txt"
    
    @classmethod 
    def get_data_save_path(cls, date_str: str = None) -> str:
        """è·å–ä¸»è¦æ•°æ®ä¿å­˜è·¯å¾„"""
        return cls.get_csv_save_path(date_str)
    
    # æŸ¥è¯¢ç­‰å¾…æ—¶é—´
    QUERY_SLEEP_SECONDS = 3
    MAIN_RETRY_SLEEP_SECONDS = 10

# æ—¥å¿—é…ç½®
logger = get_logger("stock_pool", "logs", "stock_pool.log")




def compare_with_previous_trading_day(current_df: pd.DataFrame, date_str: str = None) -> str:
    """ä¸å‰ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®è¿›è¡Œå¯¹æ¯”ï¼Œè¿”å›å¯¹æ¯”æ¶ˆæ¯"""
    if date_str is None:
        date_str = datetime.now().strftime('%Y%m%d')
    
    # è·å–å‰ä¸€äº¤æ˜“æ—¥æ•°æ®
    previous_date = trading_calendar.get_previous_trading_day(date_str)
    if not previous_date:
        return f"ğŸ“Š ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å®Œæˆ\næ•°æ®é‡: {len(current_df)}åªè‚¡ç¥¨\nâš ï¸ æœªæ‰¾åˆ°å‰ä¸€äº¤æ˜“æ—¥æ•°æ®"
    
    # æŸ¥æ‰¾å‰ä¸€äº¤æ˜“æ—¥çš„CSVæ–‡ä»¶
    previous_date_str = previous_date.strftime('%Y%m%d')
    previous_file = StockPoolConfig.get_csv_save_path(previous_date_str)
    
    if not os.path.exists(previous_file):
        return f"ğŸ“Š ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å®Œæˆ\næ•°æ®é‡: {len(current_df)}åªè‚¡ç¥¨\nâš ï¸ æœªæ‰¾åˆ°å‰ä¸€äº¤æ˜“æ—¥æ•°æ®æ–‡ä»¶"
    
    try:
        # è¯»å–CSVæ–‡ä»¶ï¼ŒæŒ‡å®šè‚¡ç¥¨ä»£ç åˆ—ä¸ºå­—ç¬¦ä¸²ç±»å‹ä»¥ä¿æŒå‰å¯¼é›¶
        previous_df = pd.read_csv(previous_file, dtype={'code': str, 'market_code': str})
    except Exception as e:
        logger.warning(f"è¯»å–å‰ä¸€äº¤æ˜“æ—¥æ•°æ®å¤±è´¥: {e}")
        return f"ğŸ“Š ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å®Œæˆ\næ•°æ®é‡: {len(current_df)}åªè‚¡ç¥¨\nâš ï¸ è¯»å–å‰ä¸€äº¤æ˜“æ—¥æ•°æ®å¤±è´¥"
    
    # åŸºäºè‚¡ç¥¨ä»£ç è®¡ç®—å˜åŠ¨ï¼ˆç¡®ä¿å”¯ä¸€æ€§ï¼‰
    current_codes = set(current_df['code'].astype(str))
    previous_codes = set(previous_df['code'].astype(str))
    
    # è·å–æ–°å¢å’Œç§»é™¤çš„è‚¡ç¥¨ä»£ç 
    new_codes = current_codes - previous_codes
    removed_codes = previous_codes - current_codes
    
    # æ„å»ºåŸºç¡€æ¶ˆæ¯
    date_fmt = f"{previous_date.strftime('%Y-%m-%d')}"
    message = [
        "ğŸ“Š æ¯æ—¥å¤ç›˜:è‚¡ç¥¨æ± ",
        f"ğŸ“… å¯¹æ¯”åŸºå‡†: {date_fmt}",
        f"ğŸ“ˆ ä»Šæ—¥: {len(current_codes)}åª | æ˜¨æ—¥: {len(previous_codes)}åª"
    ]
    
    if len(new_codes) == 0 and len(removed_codes) == 0:
        message.append("âœ¨ è‚¡ç¥¨æ± æ— å˜åŠ¨")
    else:
        # æ–°å¢è‚¡ç¥¨è¯¦æƒ…
        if len(new_codes) > 0:
            message.append(f"ğŸ†• æ–°å¢: {len(new_codes)}åª")
            
            # è·å–æ–°å¢è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
            new_stocks_info = current_df[current_df['code'].astype(str).isin(new_codes)].copy()
            new_stocks_info = new_stocks_info.sort_values('é‡è¦åº¦', ascending=False)
            
            for _, stock in new_stocks_info.iterrows():
                code = stock['code']
                name = stock['è‚¡ç¥¨ç®€ç§°']
                interval_info = stock.get('åŒºé—´ä¿¡æ¯', 'æ— ')
                message.append(f"  â€¢ {name}({code}) åŒºé—´:{interval_info}")
        
        # ç§»é™¤è‚¡ç¥¨ç»Ÿè®¡
        if len(removed_codes) > 0:
            message.append(f"ğŸ”» ç§»é™¤: {len(removed_codes)}åª")
            
            # è·å–ç§»é™¤è‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä»å‰ä¸€å¤©çš„æ•°æ®ä¸­ï¼‰
            removed_stocks_info = previous_df[previous_df['code'].astype(str).isin(removed_codes)].copy()
            removed_stocks_info = removed_stocks_info.sort_values('é‡è¦åº¦', ascending=False)
            
            for _, stock in removed_stocks_info.iterrows():
                code = stock['code']
                name = stock['è‚¡ç¥¨ç®€ç§°']
                interval_info = stock.get('åŒºé—´ä¿¡æ¯', 'æ— ')
                message.append(f"  â€¢ {name}({code}) åŒºé—´:{interval_info}")
    
    msg = "\n".join(message)
    logger.info(msg)
    return msg



def calc_importance(df: pd.DataFrame, 
                   alpha: float = None, 
                   beta: float = None) -> pd.DataFrame:
    """
    åŸºäºåŸå§‹æ•°æ®èšåˆå¹¶è®¡ç®—è‚¡ç¥¨é‡è¦åº¦
    
    Args:
        df: åŒ…å«è‚¡ç¥¨åŒºé—´æ•°æ®çš„DataFrame
        alpha: æ’åæƒé‡å‚æ•°ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒæ’åå·®è·
        beta: åŒºé—´é•¿åº¦æƒé‡å‚æ•°ï¼Œè¶Šå¤§è¶Šå¼ºè°ƒçŸ­åŒºé—´
    
    Returns:
        æŒ‰é‡è¦åº¦æ’åºçš„DataFrameï¼ŒåŒ…å«åŒºé—´ä¿¡æ¯å’Œé‡è¦åº¦å¾—åˆ†
        
    è®¡ç®—é€»è¾‘:
        1. åˆ†ç»„å­—æ®µ: [äº¤æ˜“æ—¥æœŸ, è‚¡ç¥¨ç®€ç§°, market_code, code]
        2. åŒºé—´ä¿¡æ¯: 'åŒºé—´é•¿åº¦-åŒºé—´æ’å' ç”¨ | è¿æ¥
        3. é‡è¦åº¦: 100 * sum(exp(-alpha * æ’å) * exp(-beta * åŒºé—´é•¿åº¦))
        4. æ’åº: æŒ‰é‡è¦åº¦é™åº
    """
    # ä½¿ç”¨é…ç½®é»˜è®¤å€¼
    if alpha is None:
        alpha = StockPoolConfig.IMPORTANCE_ALPHA
    if beta is None:
        beta = StockPoolConfig.IMPORTANCE_BETA
    
    logger.info(f"å¼€å§‹è®¡ç®—è‚¡ç¥¨é‡è¦åº¦, æ•°æ®é‡: {len(df)}, alpha: {alpha}, beta: {beta}")
    start_time = time.time()
    
    def aggregate_importance(sub_df):
        """èšåˆå‡½æ•°ï¼šè®¡ç®—å•åªè‚¡ç¥¨çš„é‡è¦åº¦"""
        interval_info = "|".join(
            f"{length}-{rank}" for length, rank in zip(sub_df["åŒºé—´é•¿åº¦"], sub_df["åŒºé—´æ’å"])
        )
        
        # é‡è¦åº¦è®¡ç®—ï¼šä½¿ç”¨æŒ‡æ•°è¡°å‡
        importance_score = float(100 * (
            np.exp(-alpha * sub_df["åŒºé—´æ’å"]) * 
            np.exp(-beta * sub_df["åŒºé—´é•¿åº¦"])
        ).sum())
        
        return pd.Series({
            "åŒºé—´ä¿¡æ¯": interval_info,
            "é‡è¦åº¦": importance_score
        })

    # æŒ‰è‚¡ç¥¨åˆ†ç»„å¹¶è®¡ç®—é‡è¦åº¦
    grouped_df = (
        df.groupby(["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ç®€ç§°", "market_code", "code"], as_index=False)
        .apply(aggregate_importance)
    )

    # æŒ‰é‡è¦åº¦é™åºæ’åº
    grouped_df.sort_values(by="é‡è¦åº¦", ascending=False, inplace=True)
    grouped_df.reset_index(drop=True, inplace=True)
    
    processing_time = time.time() - start_time
    logger.info(f"é‡è¦åº¦è®¡ç®—å®Œæˆ, è€—æ—¶: {processing_time:.2f}ç§’, ç»“æœæ•°é‡: {len(grouped_df)}")
    
    return grouped_df[["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ç®€ç§°", "market_code", "code", "åŒºé—´ä¿¡æ¯", "é‡è¦åº¦"]]



def execute_with_retry(func, *args, **kwargs):
    """
    å¸¦é‡è¯•æœºåˆ¶çš„å‡½æ•°åŒ…è£…å™¨
    
    Args:
        func: è¦æ‰§è¡Œçš„å‡½æ•°
        *args, **kwargs: å‡½æ•°å‚æ•°
    
    Returns:
        å‡½æ•°æ‰§è¡Œç»“æœ
        
    Raises:
        æœ€åä¸€æ¬¡å¤±è´¥çš„å¼‚å¸¸
    """
    last_exception = None
    retry_count = StockPoolConfig.MAX_RETRY_COUNT
    func_name = getattr(func, '__name__', str(func))
    
    logger.info(f"å¼€å§‹æ‰§è¡Œå‡½æ•° {func_name}, æœ€å¤§é‡è¯•æ¬¡æ•°: {retry_count}")
    
    for i in range(retry_count):
        try:
            logger.debug(f"ç¬¬{i + 1}æ¬¡å°è¯•æ‰§è¡Œ {func_name}")
            result = func(*args, **kwargs)
            
            if i > 0:
                logger.info(f"å‡½æ•° {func_name} åœ¨ç¬¬{i + 1}æ¬¡å°è¯•åæˆåŠŸæ‰§è¡Œ")
            
            return result
            
        except Exception as e:
            last_exception = e
            if i < retry_count - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                wait_time = (i + 1) * StockPoolConfig.RETRY_BASE_DELAY
                logger.warning(f"å‡½æ•° {func_name} ç¬¬{i + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•: {e}")
                time.sleep(wait_time)
            else:
                logger.error(f"å‡½æ•° {func_name} é‡è¯•{retry_count}æ¬¡åä»å¤±è´¥: {e}")
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºæœ€åçš„å¼‚å¸¸
    raise last_exception
    

def get_stock_pool(selected=False):
    """
    è·å–è‚¡ç¥¨æ± æ•°æ®ï¼Œé€šè¿‡å¤šä¸ªæ—¶é—´åŒºé—´ç»„åˆè®¡ç®—é‡è¦åº¦
    
    Args:
        selected: æ˜¯å¦ä½¿ç”¨ç­›é€‰æ¡ä»¶ï¼ˆéSTã€éé€€å¸‚ç­‰ï¼‰
    
    Returns:
        æŒ‰é‡è¦åº¦æ’åºçš„è‚¡ç¥¨æ± DataFrame
    """
    try:
        all_df = []
        # ä½¿ç”¨é…ç½®ç±»ä¸­çš„åŒºé—´è®¾ç½®
        for days, rank in StockPoolConfig.INTERVAL_CONFIGS:
            logger.info(f'========== selected: {selected}  {days}-{rank} ===========')
            df = execute_with_retry(WencaiUtils.get_top_stocks, days=days, rank=rank, use_filters=selected)
            if df is None or df.empty:
                raise Exception(f'{(days,rank)}è·å–æ•°æ®å¤±è´¥')
            all_df.append(df)
            time.sleep(StockPoolConfig.QUERY_SLEEP_SECONDS)
        
        df_all = pd.concat(all_df)
        df = calc_importance(df_all, 
                           alpha=StockPoolConfig.IMPORTANCE_ALPHA, 
                           beta=StockPoolConfig.IMPORTANCE_BETA)
        return df
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨æ± å¤±è´¥: {e}")
        return None

def save_stock_pool_codes(df: pd.DataFrame, date_str: str = None) -> str:
    """
    å°†è‚¡ç¥¨æ± çš„ä»£ç ä¿å­˜ä¸ºtxtæ–‡ä»¶
    
    Args:
        df: åŒ…å«è‚¡ç¥¨æ•°æ®çš„DataFrame
        date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
    
    Returns:
        ä¿å­˜çš„txtæ–‡ä»¶è·¯å¾„
    """
    if date_str is None:
        date_str = datetime.now().strftime('%Y%m%d')
    
    logger.info(f"å¼€å§‹ä¿å­˜è‚¡ç¥¨æ± ä»£ç åˆ°txtæ–‡ä»¶, è‚¡ç¥¨æ•°é‡: {len(df)}")
    start_time = time.time()
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—
    if 'code' not in df.columns:
        raise ValueError("DataFrameä¸­ç¼ºå°‘'code'åˆ—")
    
    # è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¹¶ç¡®ä¿æ ¼å¼æ­£ç¡®ï¼ˆ6ä½æ•°å­—ï¼‰
    stock_codes = df['code'].astype(str).str.zfill(6).tolist()
    
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    txt_path = StockPoolConfig.get_txt_save_path(date_str)
    txt_dir = os.path.dirname(txt_path)
    os.makedirs(txt_dir, exist_ok=True)
    
    # ä¿å­˜ä»£ç åˆ°txtæ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªä»£ç 
    with open(txt_path, 'w', encoding='utf-8') as f:
        for code in stock_codes:
            f.write(f"{code}\n")
    
    processing_time = time.time() - start_time
    logger.info(f"è‚¡ç¥¨æ± ä»£ç ä¿å­˜å®Œæˆ, è€—æ—¶: {processing_time:.2f}ç§’, ä¿å­˜è·¯å¾„: {txt_path}")
    
    return txt_path

def main():
    """
    ä¸»å‡½æ•°ï¼šè·å–è‚¡ç¥¨æ± æ•°æ®å¹¶ä¿å­˜
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
    2. è·å–å…¨é‡è‚¡ç¥¨æ± æ•°æ®ï¼ˆæ— ç­›é€‰ï¼‰
    3. è·å–ç­›é€‰åçš„è‚¡ç¥¨æ± æ•°æ®ï¼ˆæœ‰ç­›é€‰æ¡ä»¶ï¼‰  
    4. åˆå¹¶æ•°æ®å¹¶å»é‡ï¼ˆåŒä¸€è‚¡ç¥¨ä¿ç•™é‡è¦åº¦æœ€é«˜çš„è®°å½•ï¼‰
    5. ä¿å­˜ç»“æœå¹¶å‘é€é€šçŸ¥
    """
    logger.info("å¼€å§‹æ‰§è¡Œè‚¡ç¥¨æ± æ•°æ®è·å–ä»»åŠ¡...")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
    today = datetime.now().strftime('%Y%m%d')
    if not trading_calendar.is_trading_day(today):
        logger.info(f"ä»Šæ—¥({today})éäº¤æ˜“æ—¥ï¼Œè·³è¿‡æ‰§è¡Œ")
        return
    
    for i in range(StockPoolConfig.MAX_RETRY_COUNT):
        try:
            # è·å–å…¨é‡æ•°æ®ï¼ˆæ— ç­›é€‰æ¡ä»¶ï¼‰
            logger.info("æ­¥éª¤1: è·å–å…¨é‡è‚¡ç¥¨æ± æ•°æ®")
            full_data = get_stock_pool(selected=False)
            if full_data is None or full_data.empty:
                logger.warning("å…¨é‡æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                continue
            logger.info(f'å…¨é‡æ•°æ®è·å–æˆåŠŸ, æ•°æ®é‡: {full_data.shape}')
            
            # è·å–ç­›é€‰æ•°æ®ï¼ˆæœ‰ç­›é€‰æ¡ä»¶ï¼‰
            logger.info("æ­¥éª¤2: è·å–ç­›é€‰åè‚¡ç¥¨æ± æ•°æ®")
            filtered_data = get_stock_pool(selected=True)
            if filtered_data is None or filtered_data.empty:
                logger.warning("ç­›é€‰æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å°è¯•")
                continue
            logger.info(f'ç­›é€‰æ•°æ®è·å–æˆåŠŸ, æ•°æ®é‡: {filtered_data.shape}')
            
            # åˆå¹¶å¹¶å»é‡å¤„ç†
            logger.info("æ­¥éª¤3: åˆå¹¶æ•°æ®å¹¶å»é‡")
            combined_df = pd.concat([full_data, filtered_data], ignore_index=True)
            
            # æŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œä¿ç•™é‡è¦åº¦æœ€é«˜çš„è®°å½•
            groupby_keys = ['äº¤æ˜“æ—¥æœŸ', 'è‚¡ç¥¨ç®€ç§°', 'market_code', 'code']
            max_importance_idx = combined_df.groupby(groupby_keys)['é‡è¦åº¦'].idxmax()
            final_df = (combined_df.loc[max_importance_idx]
                       .sort_values(by='é‡è¦åº¦', ascending=False)
                       .reset_index(drop=True))
            
            # æ­¥éª¤4: æ•°æ®å¯¹æ¯”åˆ†æ
            logger.info("æ­¥éª¤4: ä¸å‰ä¸€äº¤æ˜“æ—¥æ•°æ®è¿›è¡Œå¯¹æ¯”åˆ†æ")
            comparison_msg = compare_with_previous_trading_day(final_df)
            
            # æ­¥éª¤5: ä¿å­˜æ•°æ®
            logger.info("æ­¥éª¤5: ä¿å­˜æ•°æ®")
            save_path = StockPoolConfig.get_csv_save_path()
            # åˆ›å»ºæ‰€éœ€çš„ç›®å½•ç»“æ„
            os.makedirs(f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.CSV_SUBDIR}", exist_ok=True)
            os.makedirs(f"{StockPoolConfig.DATA_SAVE_DIR}/{StockPoolConfig.TXT_SUBDIR}", exist_ok=True)
            
            # ä¿å­˜ä¸ºCSVæ ¼å¼ï¼Œèƒ½æ›´å¥½åœ°ä¿æŒæ•°æ®ç±»å‹
            final_df.to_csv(save_path, index=False, encoding='utf-8-sig')

            # æ­¥éª¤6: ä¿å­˜è‚¡ç¥¨æ± ä»£ç åˆ°txtæ–‡ä»¶
            logger.info("æ­¥éª¤6: ä¿å­˜è‚¡ç¥¨æ± ä»£ç åˆ°txtæ–‡ä»¶")
            save_stock_pool_codes(final_df)
            
            # æ­¥éª¤7: å‘é€å¯¹æ¯”ç»“æœé€šçŸ¥
            logger.info("æ­¥éª¤7: å‘é€æ•°æ®å¯¹æ¯”ç»“æœåˆ°é’‰é’‰")
            logger.info(f"ä»»åŠ¡å®Œæˆ! æœ€ç»ˆæ•°æ®é‡: {final_df.shape}, ä¿å­˜è·¯å¾„: {save_path}")
            send_dingding_msg(comparison_msg)
            return  # æˆåŠŸå®Œæˆï¼Œé€€å‡ºå‡½æ•°
            
        except Exception as e:
            if i == StockPoolConfig.MAX_RETRY_COUNT - 1:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                error_msg = f"æ¯æ—¥å¤ç›˜ \n ä»Šæ—¥è‚¡ç¥¨æ± æ›´æ–°å¤±è´¥: {e}"
                logger.error(f"é‡è¯•{StockPoolConfig.MAX_RETRY_COUNT}æ¬¡åä»å¤±è´¥: {e}")
                send_dingding_msg(error_msg)
            else:
                # è¿˜æœ‰é‡è¯•æœºä¼š
                logger.warning(f"ç¬¬{i+1}æ¬¡å°è¯•å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•: {e}")
            
            if i < StockPoolConfig.MAX_RETRY_COUNT - 1:
                time.sleep(StockPoolConfig.MAIN_RETRY_SLEEP_SECONDS)

if __name__ == "__main__":
    main()